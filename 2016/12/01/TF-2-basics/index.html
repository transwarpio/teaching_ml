<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      TF-2-basics | Teaching ML 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="transwarpio">
    
    

    <meta name="description" content="Previous Chapter: Style GuideNext Chapter: Graph Basic ConcptsFollowing part is quoted from Tensorflow 2015 White Paper. A TensorFlow computation is described by a directed graph, which is composed of">
<meta property="og:type" content="article">
<meta property="og:title" content="TF-2-basics | Teaching ML">
<meta property="og:url" content="http://transwarpio.github.io/2016/12/01/TF-2-basics/index.html">
<meta property="og:site_name" content="Teaching ML">
<meta property="og:description" content="Previous Chapter: Style GuideNext Chapter: Graph Basic ConcptsFollowing part is quoted from Tensorflow 2015 White Paper. A TensorFlow computation is described by a directed graph, which is composed of">
<meta property="og:image" content="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/3.png">
<meta property="og:image" content="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/2.png">
<meta property="og:image" content="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/1.png">
<meta property="og:updated_time" content="2017-08-09T08:31:23.097Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TF-2-basics | Teaching ML">
<meta name="twitter:description" content="Previous Chapter: Style GuideNext Chapter: Graph Basic ConcptsFollowing part is quoted from Tensorflow 2015 White Paper. A TensorFlow computation is described by a directed graph, which is composed of">
<meta name="twitter:image" content="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/3.png">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/teaching_ml/css/uno.css">
    <link rel="stylesheet" href="/teaching_ml/css/highlight.css">
    <link rel="stylesheet" href="/teaching_ml/css/archive.css">
    <link rel="stylesheet" href="/teaching_ml/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Teaching ML</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">TF-2-basics</h1>

    

    <div class="post-meta">
      <time datetime="2016-12-01" class="post-meta__date date">2016-12-01</time> 

      <span class="post-meta__tags tags">

          

          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <p><a href="../TF-1-style">Previous Chapter: Style Guide</a><br><a href="../TF-3-graph">Next Chapter: Graph</a></p>
<h2 id="Basic-Concpts"><a href="#Basic-Concpts" class="headerlink" title="Basic Concpts"></a>Basic Concpts</h2><p>Following part is quoted from <a href="http://download.tensorflow.org/paper/whitepaper2015.pdf" target="_blank" rel="external">Tensorflow 2015 White Paper</a>.</p>
<p><span style="color: #F08080">A <strong>TensorFlow computation</strong> is described by a <strong>directed graph</strong>, which is composed of a set of nodes</span>. The <em>graph</em> represents a dataflow computation, with extensions for allowing some kinds of nodes to maintain and update persistent state and for branching and looping control structures within the graph. Clients typically construct a computational graph using one of the supported frontend languages (C++ or<br>Python).</p>
<p><img src="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/3.png" width="200"><br><img src="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/2.png" width="800"></p>
<p>In a <em>TensorFlow graph</em>, <span style="color: #F08080">each <strong>node</strong> represents the instantiation of an <strong>operation</strong>, and has zero or more inputs and zero or more outputs</span>. <span style="color: #F08080">Values that flow along normal edges in the graph (from outputs to inputs) are <strong>tensors</strong></span>, arbitrary dimensionality arrays where the underlying element type is specified or inferred at graph-construction time.</p>
<h3 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h3><p><span style="color: #F08080">A tensor is a typed, multidimensional array</span>. Tensorflow support a variety of tensor element types, including signed and unsigned integers ranging in size from 8 bits to 64 bits, IEEE float and double types, a complex number type, and a string type (an arbitrary byte array). Backing store of the appropriate size is managed by an allocator that is specific to the device on which the tensor resides. Tensor backing store buffers are reference counted and are deallocated when no references remain.</p>
<h3 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h3><p>In most computations a graph is executed multiple times. Most <strong>tensors</strong> do not survive past a single execution of the graph. However, <span style="color: #F08080">a <strong>Variable</strong> is a special kind of operation that returns a handle to a persistent mutable tensor that survives across executions of a graph</span>. Handles to these persistent mutable tensors can be passed to a handful of special operations, such as Assign and AssignAdd (equivalent to +=) that mutate the referenced tensor.</p>
<h3 id="Operations-Ops"><a href="#Operations-Ops" class="headerlink" title="Operations(Ops)"></a>Operations(Ops)</h3><p><span style="color: #F08080">An <strong>operation</strong> has a name and represents an abstract computation (see the following table)</span>. An operation can have attributes, and all attributes must be provided or inferred at graph-construction time in order to instantiate a node to perform the operation.<br><span style="color: #F08080">A <strong>kernel</strong> is a particular implementation of an operation that can be run on a particular type of device (e.g., CPU or GPU)</span>.</p>
<p><img src="https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/1.png" width="800"></p>
<h3 id="Sessions"><a href="#Sessions" class="headerlink" title="Sessions"></a>Sessions</h3><p><span style="color: #F08080">Clients programs interact with the TensorFlow system by creating a <strong>Session</strong></span>.</p>
<p><strong>Session Run</strong>, which takes a set of output names that need to be computed, as well as an optional set of tensors to be fed into the graph in place of certain outputs of nodes. Using the arguments to Run, the TensorFlow implementation can compute the transitive closure of all nodes that must be executed in order to compute the outputs that were requested, and can then arrange to execute the appropriate nodes in an order that respects their dependencies. <span style="color: #F08080">Most of our uses of TensorFlow set up a Session with a graph once, and then execute the full graph or a few distinct subgraphs thousands or millions of times via <strong>Run</strong> calls.</span></p>
<h3 id="Single-Device-Execution"><a href="#Single-Device-Execution" class="headerlink" title="Single Device Execution"></a>Single Device Execution</h3><p>Let&#x2019;s first consider the simplest execution scenario: a single worker process with a single device. The nodes of the graph are executed in an order that respects the dependencies between nodes. In particular, <span style="color: #F08080">Tensorflow keeps track of a count per node of the number of dependencies of that node that have not yet been executed. Once this count drops to zero, the node is eligible for execution and is added to a ready queue</span>. The ready queue is processed in some unspecified order, delegating execution of the kernel for a node to the device object. When a node has finished executing, the counts of all nodes that depend on the completed node are decremented.</p>
<h3 id="Exercise-Basic-Concepts"><a href="#Exercise-Basic-Concepts" class="headerlink" title="Exercise: Basic Concepts"></a>Exercise: Basic Concepts</h3><p>Read the below <strong>Tensorflow API</strong> carefully and finish the exerceses.</p>
<h5 id="tf-Session-run-fetches-feed-dict-None-options-None-run-metadata-None"><a href="#tf-Session-run-fetches-feed-dict-None-options-None-run-metadata-None" class="headerlink" title="tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None)"></a>tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">Runs operations and evaluates tensors in fetches.</div><div class="line"></div><div class="line">The fetches argument can be one of the following types:</div><div class="line">- An Operation;</div><div class="line">- A Tensor;</div><div class="line">- A SparseTensor;</div><div class="line">- A get_tensor_handle op;</div><div class="line">- A string which is the name of a tensor or operation in graph;</div><div class="line"></div><div class="line">Returns</div><div class="line">- A single value if fetches is a single graph element;</div><div class="line">- A list of values if fetches is a list;</div><div class="line">- A dictionary with the same keys;</div></pre></td></tr></table></figure>
<h5 id="tf-constant-value-dtype-None-shape-None-name-&#x2019;Const&#x2019;"><a href="#tf-constant-value-dtype-None-shape-None-name-&#x2019;Const&#x2019;" class="headerlink" title="tf.constant(value, dtype=None, shape=None, name=&#x2019;Const&#x2019;)"></a>tf.constant(value, dtype=None, shape=None, name=&#x2019;Const&#x2019;)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Creates a constant tensor.</div><div class="line"></div><div class="line">The argument value can be</div><div class="line">- A constant value;</div><div class="line">- A list of values of type dtype; </div><div class="line"></div><div class="line">The resulting tensor is populated with values of type dtype.</div></pre></td></tr></table></figure>
<h5 id="tf-placeholder-dtype-shape-None-name-None"><a href="#tf-placeholder-dtype-shape-None-name-None" class="headerlink" title="tf.placeholder(dtype, shape=None, name=None)"></a>tf.placeholder(dtype, shape=None, name=None)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Inserts a placeholder for a tensor that will be always fed.</div><div class="line"></div><div class="line">Important: This tensor will produce an error if evaluated.</div><div class="line">Its value must be fed using the feed_dict optional argument</div><div class="line">to Session.run(), Tensor.eval(), or Operation.run().</div></pre></td></tr></table></figure>
<h5 id="tf-matmul-a-b-transpose-a-False-transpose-b-False-a-is-sparse-False-b-is-sparse-False-name-None"><a href="#tf-matmul-a-b-transpose-a-False-transpose-b-False-a-is-sparse-False-b-is-sparse-False-name-None" class="headerlink" title="tf.matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None)"></a>tf.matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Multiplies matrix a by matrix b, producing a * b.</div><div class="line"></div><div class="line">The inputs must be</div><div class="line">- Two-dimensional matching matrices;</div><div class="line">- Both matrices must be of the same type</div><div class="line">  (float32, float64, int32, complex64)</div><div class="line"></div><div class="line">Either matrix can be transposed on the fly by setting the</div><div class="line">corresponding flag to True.</div><div class="line"></div><div class="line">If one or both of the matrices contain a lot of zeros, please</div><div class="line">set the corresponding a_is_sparse or b_is_sparse flag to True.</div></pre></td></tr></table></figure>
<h4 id="Prepare-for-Coding"><a href="#Prepare-for-Coding" class="headerlink" title="Prepare for Coding"></a>Prepare for Coding</h4><p>At first, let&#x2019;s follow the <a href="1-style.ipynb">style guide</a> and put the necessary headers.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div></pre></td></tr></table></figure>
<p>Get a session to run the code.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div></pre></td></tr></table></figure>
<h4 id="Constants"><a href="#Constants" class="headerlink" title="Constants"></a>Constants</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## create two variables `a = 2` and `b = 3`</span></div><div class="line">a = ... <span class="comment">###### write your code here ######</span></div><div class="line">b = ... <span class="comment">###### write your code here ######</span></div><div class="line"></div><div class="line">resultA = sess.run(a)</div><div class="line">resultB = sess.run(b)</div><div class="line"></div><div class="line"><span class="comment"># see the result and its type</span></div><div class="line">print(<span class="string">&quot;a = %i with tpye of %s&quot;</span> % (resultA, type(resultA)))</div><div class="line">print(<span class="string">&quot;b = %i with tpye of %s&quot;</span> % (resultB, type(resultB)))</div></pre></td></tr></table></figure>
<h4 id="Arrays-and-Matrices"><a href="#Arrays-and-Matrices" class="headerlink" title="Arrays and Matrices"></a>Arrays and Matrices</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## create two matrixes `c = {{1, 2}, {3, 4}}` and `d = {{1, 1}, {0, 1}}`</span></div><div class="line">c = ... <span class="comment">###### write your code here ######</span></div><div class="line">d = ... <span class="comment">###### write your code here ######</span></div><div class="line"></div><div class="line">resultC = sess.run(c)</div><div class="line">resultCD = sess.run([c, d])</div><div class="line"></div><div class="line"><span class="comment"># see the result and its type</span></div><div class="line">print(resultC)</div><div class="line">print(type(resultC))</div><div class="line">print(resultCD)</div><div class="line">print(type(resultCD))</div></pre></td></tr></table></figure>
<h4 id="String"><a href="#String" class="headerlink" title="String"></a>String</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## create a string `e = &apos;Hello, Tensorflow&apos;`</span></div><div class="line">e = ... <span class="comment">###### write your code here ######</span></div><div class="line">print(sess.run(e))</div></pre></td></tr></table></figure>
<h4 id="Matrice-Multipulation"><a href="#Matrice-Multipulation" class="headerlink" title="Matrice Multipulation"></a>Matrice Multipulation</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## multply c and d using `tf.matmul()`</span></div><div class="line">mul = ... <span class="comment">###### write your code here ######</span></div><div class="line">print(sess.run(mul))</div></pre></td></tr></table></figure>
<h4 id="Placeholders"><a href="#Placeholders" class="headerlink" title="Placeholders"></a>Placeholders</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## create two placeholder `f` and `g` holds `tf.int16`</span></div><div class="line">f = ... <span class="comment">###### write your code here ######</span></div><div class="line">g = ... <span class="comment">###### write your code here ######</span></div><div class="line"></div><div class="line"><span class="comment">## some operations</span></div><div class="line">add = tf.add(f, g)</div><div class="line">mul = tf.mul(f, g)</div><div class="line"></div><div class="line"><span class="comment"># get the result of add by feeding `{f: 2, g: 3}` to `sess.run()` using feed_dict</span></div><div class="line">resultAdd, resultMul = ... <span class="comment">###### write your code here ######</span></div><div class="line">print(<span class="string">&quot;adding result is: %i&quot;</span> % resultAdd)</div><div class="line">print(<span class="string">&quot;multiplying result is: %i&quot;</span> % resultMul)</div></pre></td></tr></table></figure>
<p><a href="../TF-1-style">Previous Chapter: Style Guide</a><br><a href="../TF-3-graph">Next Chapter: Graph</a></p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/teaching_ml/js/jquery.min.js"></script>
    <script src="/teaching_ml/js/main.js"></script>
    <script src="/teaching_ml/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/teaching_ml/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
