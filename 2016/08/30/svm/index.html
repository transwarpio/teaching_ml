<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Support Vector Machine | Teaching ML</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1 SVM   1.1 &amp;#x4ECB;&amp;#x7ECD;   Support Vector Machine &amp;#x652F;&amp;#x6301;&amp;#x5411;&amp;#x91CF;&amp;#x673A;&amp;#x662F;&amp;#x4E00;&amp;#x79CD;&amp;#x673A;&amp;#x5668;&amp;#x5B66;&amp;#x4E60;&amp;#x7B97;&amp;#x6CD5;&amp;#x3002;     &amp;#x7ED9;&amp;#x5B9A;&amp;">
<meta property="og:type" content="article">
<meta property="og:title" content="Support Vector Machine">
<meta property="og:url" content="http://transwarpio.github.io/2016/08/30/svm/index.html">
<meta property="og:site_name" content="Teaching ML">
<meta property="og:description" content="1 SVM   1.1 &amp;#x4ECB;&amp;#x7ECD;   Support Vector Machine &amp;#x652F;&amp;#x6301;&amp;#x5411;&amp;#x91CF;&amp;#x673A;&amp;#x662F;&amp;#x4E00;&amp;#x79CD;&amp;#x673A;&amp;#x5668;&amp;#x5B66;&amp;#x4E60;&amp;#x7B97;&amp;#x6CD5;&amp;#x3002;     &amp;#x7ED9;&amp;#x5B9A;&amp;">
<meta property="og:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/svm.png">
<meta property="og:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/tree.png">
<meta property="og:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/2d_linear.png">
<meta property="og:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/3d_linear.png">
<meta property="og:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/step1.png">
<meta property="og:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/step2.png">
<meta property="og:updated_time" content="2017-08-09T08:31:23.109Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Support Vector Machine">
<meta name="twitter:description" content="1 SVM   1.1 &amp;#x4ECB;&amp;#x7ECD;   Support Vector Machine &amp;#x652F;&amp;#x6301;&amp;#x5411;&amp;#x91CF;&amp;#x673A;&amp;#x662F;&amp;#x4E00;&amp;#x79CD;&amp;#x673A;&amp;#x5668;&amp;#x5B66;&amp;#x4E60;&amp;#x7B97;&amp;#x6CD5;&amp;#x3002;     &amp;#x7ED9;&amp;#x5B9A;&amp;">
<meta name="twitter:image" content="http://transwarpio.github.io/teaching_ml/2016/08/30/svm/svm.png">
  
    <link rel="alternate" href="/atom.xml" title="Teaching ML" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/teaching_ml/css/style.css">
  

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/teaching_ml/" id="logo">Teaching ML</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/teaching_ml/">Home</a>
        
          <a class="main-nav-link" href="/teaching_ml/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://transwarpio.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-svm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/teaching_ml/2016/08/30/svm/" class="article-date">
  <time datetime="2016-08-30T00:00:00.000Z" itemprop="datePublished">2016-08-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Support Vector Machine
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        


<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> SVM</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> &#x4ECB;&#x7ECD;</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Support Vector Machine &#x652F;&#x6301;&#x5411;&#x91CF;&#x673A;&#x662F;&#x4E00;&#x79CD;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x3002; 
</p>

<p>
&#x7ED9;&#x5B9A;&#x4E00;&#x4E2A;&#x8BAD;&#x7EC3;&#x96C6; \( S = \{ (x_i, y_i) \}_{i=1}^{m} \), &#x5176;&#x4E2D; \( x_i \in \mathbb{R}^n \) &#x5E76;&#x4E14; \( y_i \in \{ +1, -1 \} \),
&#x56FE;<a href="#svm">1</a>&#x5C55;&#x793A;&#x4E86;&#x4E00;&#x4E2A; SVM &#x9700;&#x8981;&#x89E3;&#x51B3;&#x7684;&#x95EE;&#x9898;&#x3002; &#x6211;&#x4EEC;&#x6807;&#x8BB0;  \( w \cdot x - b = 0 \) &#x4E3A;&#x8D85;&#x5E73;&#x9762;&#xFF0C; \( w \) &#x4EE3;&#x8868;&#x8BE5;&#x8D85;&#x5E73;&#x9762;&#x7684;&#x5411;&#x91CF;&#x3002; 
&#x6211;&#x4EEC;&#x9700;&#x8981;&#x505A;&#x7684;&#x662F;&#x627E;&#x5230;&#x80FD;&#x5C06; \( y_i=1 \) &#x7684;&#x70B9;&#x548C; \( y_i=-1 \) &#x7684;&#x70B9; &#x5206;&#x5F00;&#x7684;&#x8FB9;&#x9645;&#x6700;&#x5927;&#x7684;&#x8D85;&#x5E73;&#x9762;.
&#x8FD9;&#x5C31;&#x610F;&#x5473;&#x7740; \( y_i(w \cdot x_i -b ) \geq 1 \)&#xFF0C;&#x5BF9;&#x4E8E;&#x6240;&#x6709; \( 1 \leq i \leq n \).
</p>

<p>
&#x6240;&#x4EE5;&#x4F18;&#x5316;&#x95EE;&#x9898;&#x53EF;&#x4EE5;&#x5199;&#x6210;&#xFF1A;
</p>

<p>
&#x6700;&#x5927;&#x5316;
</p>

<p>
\[ \frac{2}{\|w\|} \]
</p>

<p>
&#x8FD9;&#x7B49;&#x4EF7;&#x4E8E;&#x6700;&#x5C0F;&#x5316;
</p>

<p>
\[ \frac{1}{2} \| w \|^2 \]
</p>

<p>
subject to \( y_i(w \cdot x_i - b) \geq 1 \) for all \( 1 \leq i \leq n \)
</p>


<div id="svm" class="figure">
<p><img src="/teaching_ml/2016/08/30/svm/svm.png" alt="captionm" width="400px">
</p>
<p><span class="figure-number">Figure 1:</span> SVM</p>
</div>

<p>
&#x4E8B;&#x5B9E;&#x4E0A;&#xFF0C;&#x5B83;&#x53EF;&#x4EE5;&#x88AB;&#x770B;&#x4F5C;&#x4E00;&#x4E2A;&#x5E26;&#x6709;&#x60E9;&#x7F5A;&#x9879;&#x7684;&#x6700;&#x5C0F;&#x5316;&#x635F;&#x5931;&#x95EE;&#x9898;&#x3002;&#x6700;&#x7EC8;&#xFF0C;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x627E;&#x5230;&#x4EE5;&#x4E0B;&#x95EE;&#x9898;&#x7684;&#x6700;&#x5C0F;&#x89E3;
</p>

<p>
\[
 \min_{w} \frac{\lambda}{2}\|w\|^2 + \frac{1}{m}\sum_{(x, y) \in S} \ell(w; (x, y))
\]
</p>

<p>
&#x5176;&#x4E2D; &#x3BB; &#x662F;&#x6B63;&#x89C4;&#x5316;&#x53C2;&#x6570;, \( \ell(w, (x, y)) \) &#x662F; hinge &#x635F;&#x5931;&#x51FD;&#x6570;:
</p>

<p>
\[
\ell(w, (x, y)) = max\{0, 1-y \langle w, x \rangle \}
\]
</p>

<p>
&#x5BF9;&#x4E8E;&#x8FD9;&#x4E00;&#x6700;&#x4F18;&#x5316;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x6765;&#x8FBE;&#x5230;&#x6700;&#x5C0F;&#x503C;&#x3002;
</p>

<p>
&#x76EE;&#x6807;&#x51FD;&#x6570;&#x4E3A;&#xFF1A;
</p>

<p>
\[
f(w) = \frac{\lambda}{2}\|w\|^2 + \frac{1}{m}\sum_{(x_i, y_i) \in S}\ell(w; (x_i, y_i))
\]
</p>

<p>
&#x6240;&#x4EE5;&#xFF0C;&#x8FED;&#x4EE3; <i>t</i> &#x65F6;&#x7684;&#x68AF;&#x5EA6;&#x4E3A;&#xFF1A;
</p>

<p>
\[
\nabla_t = \lambda w_t - \frac{1}{m}\sum_{(x_i, y_i) \in S}\mathbbm{1}[y_i \langle w, x_i \rangle &lt; 1]y_i x_i
\]
</p>

<p>
&#x4E8E;&#x662F;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x66F4;&#x65B0;  \( w \), &#x5176;&#x4E2D; \( \eta_t \) &#x662F;&#x4E0B;&#x964D;&#x901F;&#x5EA6;
\[
w_{t+1} \leftarrow w_t - \eta_t\nabla_t
\]
</p>
</div>
</div>

<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> SGD</h3>
<div class="outline-text-3" id="text-1-2">
<p>
&#x4ECE;&#x4E0A;&#x4E00;&#x8282;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x6211;&#x4EEC;&#x90FD;&#x9700;&#x8981;&#x6240;&#x6709;&#x7684;&#x6570;&#x636E;&#x70B9;&#x6765;&#x8BA1;&#x7B97;&#x68AF;&#x5EA6;&#x3002;&#x800C;&#x5F53;&#x6570;&#x636E;&#x96C6;&#x53D8;&#x5927;&#x540E;&#xFF0C;&#x65E0;&#x7591;&#x4F1A;&#x8017;&#x8D39;&#x5927;&#x91CF;&#x7684;&#x8BA1;&#x7B97;&#x65F6;&#x95F4;&#x3002;
&#x8FD9;&#x5C31;&#x662F;&#x4E3A;&#x4EC0;&#x4E48;&#x5728;&#x5927;&#x89C4;&#x6A21;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x603B;&#x4F1A;&#x4F7F;&#x7528; SGD&#xFF08;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#xFF09;&#x3002;SDG &#x5728;&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x65F6;&#x53EA;&#x4F7F;&#x7528;&#x4E00;&#x90E8;&#x5206;&#x6570;&#x636E;&#x800C;&#x4E0D;&#x662F;&#x5168;&#x90E8;&#xFF0C;
&#x4ECE;&#x800C;&#x964D;&#x4F4E;&#x4E86;&#x8BA1;&#x7B97;&#x91CF;&#x3002;
</p>

<p>
&#x6240;&#x4EE5;&#xFF0C;&#x73B0;&#x5728;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x53D8;&#x6210;&#x4E86;&#xFF1A;
\[
f(w, A_t) = \frac{\lambda}{2}\|w\|^2 + \frac{1}{k}\sum_{(x_i, y_i) \in A_t}\ell(w; (x_i, y_i))
\]
where \( A_t \subset S \), \( |A_t| = k \). At each iteration, we takes a subset of data point.
</p>

<p>
&#x7136;&#x540E;&#x68AF;&#x5EA6;&#x4E3A;&#xFF1A;
 \[ \nabla_t = \lambda w_t - \frac{1}{k}\sum_{(x_i, y_i) \in A_t}\mathbbm{1}[y_i \langle w, x_i \rangle &lt; 1]y_i x_i \]
</p>
</div>
</div>

<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> Pegasos and MLlib implementation</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Pegasos &#x662F; SVM &#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x7684;&#x4E00;&#x79CD;&#x5B9E;&#x73B0;&#x3002;Spark MLlib &#x4E5F;&#x63D0;&#x4F9B;&#x4E86; SVM &#x7684;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x5B9E;&#x73B0;&#xFF0C;&#x4E8E; Pegasos &#x7A0D;&#x6709;&#x4E0D;&#x540C;&#x3002;
&#x4E3B;&#x8981;&#x662F;&#x68AF;&#x5EA6;&#x7684;&#x66F4;&#x65B0;&#x901F;&#x5EA6;&#x4E0D;&#x540C;&#x3002;
</p>

<p>
\[
w_{t+1} \leftarrow w_t - \eta_t\nabla_t
\]
</p>

<p>
&#x5728; Pegasos &#x7B97;&#x6CD5;&#x4E2D;, &#x66F4;&#x65B0;&#x901F;&#x5EA6;&#x4E3A;
\[
\eta_t = \frac{\alpha}{t\lambda}
\]
</p>

<p>
&#x800C;&#x5728; MLlib &#x4E2D;&#xFF0C;&#x4E3A;&#xFF1A;
\[
\eta_t = \frac{\alpha}{\sqrt{t}}
\]
</p>

<p>
&#x5176;&#x4E2D; &#x3B1; &#x662F;&#x66F4;&#x65B0;&#x901F;&#x5EA6;&#x53C2;&#x6570;&#x3002;
</p>
</div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> SGD in Spark</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> treeAggregate</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Spark &#x6765;&#x8BA1;&#x7B97; SGD &#x7684;&#x4E3B;&#x8981;&#x4F18;&#x52BF;&#x4F7F;&#x53EF;&#x4EE5;&#x5206;&#x5E03;&#x5F0F;&#x5730;&#x8BA1;&#x7B97;&#x68AF;&#x5EA6;&#xFF0C;&#x7136;&#x540E;&#x5C06;&#x5B83;&#x4EEC;&#x7D2F;&#x52A0;&#x8D77;&#x6765;&#x3002;
&#x5728; Spark &#x4E2D;&#xFF0C;&#x8FD9;&#x4E00;&#x4EFB;&#x52A1;&#x662F;&#x901A;&#x8FC7; RDD &#x7684; <b>treeAggregate</b> &#x65B9;&#x6CD5;&#x6765;&#x5B8C;&#x6210;&#x7684;&#x3002;
<b>Aggregate</b> &#x53EF;&#x88AB;&#x89C6;&#x4E3A;&#x6CDB;&#x5316;&#x7684; <b>Map</b> &#x548C; <b>Reduce</b> &#x7684;&#x7EC4;&#x5408;&#x3002; <b>treeAggregate</b> &#x7684;&#x5B9A;&#x4E49;&#x4E3A;
</p>

<div class="org-src-container">

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">RDD</span>.treeAggregate(zeroValue: <span class="type">U</span>)(</span><br><span class="line">      seqOp: (<span class="type">U</span>, <span class="type">T</span>) =&amp;gt; <span class="type">U</span>,</span><br><span class="line">      combOp: (<span class="type">U</span>, <span class="type">U</span>) =&amp;gt; <span class="type">U</span>,</span><br><span class="line">      depth: <span class="type">Int</span> = <span class="number">2</span>): <span class="type">U</span></span><br></pre></td></tr></table></figure>
</div>

<p>
&#x5728;&#x6B64;&#x65B9;&#x6CD5;&#x4E2D;&#x6709;&#x4E09;&#x4E2A;&#x53C2;&#x6570;&#xFF0C;&#x5176;&#x4E2D;&#x524D;&#x4E24;&#x4E2A;&#x5BF9;&#x6211;&#x4EEC;&#x66F4;&#x91CD;&#x8981;&#xFF1A;
</p>

<ul class="org-ul">
<li>seqOp: &#x8BA1;&#x7B97;&#x6BCF;&#x9694; partition &#x4E2D;&#x7684;&#x5B50;&#x68AF;&#x5EA6;
</li>
<li>combOp: &#x5C06; seqOp &#x6216;&#x4E0A;&#x5C42; combOp &#x7684;&#x503C;&#x5408;&#x5E76;
</li>
<li>depth: &#x63A7;&#x5236; tree &#x7684;&#x6DF1;&#x5EA6;
</li>
</ul>


<div id="tree" class="figure">
<p><img src="/teaching_ml/2016/08/30/svm/tree.png" alt="tree.png">
</p>
<p><span class="figure-number">Figure 2:</span> tree aggregate</p>
</div>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> &#x5B9E;&#x73B0;</h3>
<div class="outline-text-3" id="text-2-2">
<p>
SGD &#x662F;&#x4E00;&#x4E2A;&#x6C42;&#x6700;&#x4F18;&#x5316;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x8BB8;&#x591A;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x90FD;&#x53EF;&#x4EE5;&#x7528; SGD &#x6765;&#x6C42;&#x89E3;&#x3002;&#x6240;&#x4EE5; Spark &#x5BF9;&#x5176;&#x505A;&#x4E86;&#x62BD;&#x8C61;&#x3002;
</p>

<div class="org-src-container">

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVMWithSGD</span> <span class="title">private</span> (</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> stepSize: <span class="type">Double</span>,</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> numIterations: <span class="type">Int</span>,</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> regParam: <span class="type">Double</span>,</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">var</span> miniBatchFraction: <span class="type">Double</span>)</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">GeneralizedLinearAlgorithm</span>[<span class="type">SVMModel</span>] <span class="keyword">with</span> <span class="type">Serializable</span> {</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> gradient = <span class="keyword">new</span> <span class="type">HingeGradient</span>()</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> updater = <span class="keyword">new</span> <span class="type">SquaredL2Updater</span>()</span><br><span class="line">  <span class="annotation">@Since</span>(<span class="string">&quot;0.8.0&quot;</span>)</span><br><span class="line">  <span class="keyword">override</span> <span class="keyword">val</span> optimizer = <span class="keyword">new</span> <span class="type">GradientDescent</span>(gradient, updater)</span><br><span class="line">    .setStepSize(stepSize)</span><br><span class="line">    .setNumIterations(numIterations)</span><br><span class="line">    .setRegParam(regParam)</span><br><span class="line">    .setMiniBatchFraction(miniBatchFraction)</span><br></pre></td></tr></table></figure>
</div>

<p>
&#x53EF;&#x4EE5;&#x770B;&#x5230; <code>SVMWithSGD</code> &#x7EE7;&#x627F;&#x4E86; <code>GeneralizedLinearAlgorithm</code> &#xFF0C;&#x5E76;&#x5B9A;&#x4E49; <code>optimizer</code> &#x6765;&#x786E;&#x5B9A;&#x5982;&#x4F55;&#x83B7;&#x5F97;&#x4F18;&#x5316;&#x89E3;&#x3002;
&#x800C; <code>optimizer</code> &#x5373;&#x662F; SGD &#x7B97;&#x6CD5;&#x7684;&#x5B9E;&#x73B0;&#x3002;&#x6B63;&#x5982;&#x4E0A;&#x8282;&#x6240;&#x8FF0;&#xFF0C;&#x7EBF;&#x6027; SVM &#x5B9E;&#x9645;&#x4E0A;&#x662F;&#x4F7F;&#x7528; hinge &#x635F;&#x5931;&#x51FD;&#x6570;&#x548C;&#x4E00;&#x4E2A; L2 &#x60E9;&#x7F5A;&#x9879;&#x7684;&#x7EBF;&#x6027;&#x6A21;&#x578B;&#xFF0C;&#x56E0;&#x6B64;&#x8FD9;&#x91CC;&#x4F7F;&#x7528;&#x4E86; <code>HingeGradient</code> &#x548C; <code>SquaredL2Updater</code> 
&#x4F5C;&#x4E3A; <code>GradientDescent</code> &#x7684;&#x53C2;&#x6570;&#x3002;
</p>

<div class="org-src-container">

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HingeGradient</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">Gradient</span> {</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(</span>data: <span class="type">Vector</span>, label: <span class="type">Double</span>, weights: <span class="type">Vector</span>): (<span class="type">Vector</span>, <span class="type">Double</span>) = {</span><br><span class="line">    <span class="keyword">val</span> dotProduct = dot(data, weights)</span><br><span class="line">    <span class="comment">// Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))</span></span><br><span class="line">    <span class="comment">// Therefore the gradient is -(2y - 1)*x</span></span><br><span class="line">    <span class="keyword">val</span> labelScaled = <span class="number">2</span> * label - <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">1.0</span> &amp;gt; labelScaled * dotProduct) {</span><br><span class="line">      <span class="keyword">val</span> gradient = data.copy</span><br><span class="line">      scal(-labelScaled, gradient)</span><br><span class="line">      (gradient, <span class="number">1.0</span> - labelScaled * dotProduct)</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">      (<span class="type">Vectors</span>.sparse(weights.size, <span class="type">Array</span>.empty, <span class="type">Array</span>.empty), <span class="number">0.0</span>)</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(</span></span><br><span class="line">      data: <span class="type">Vector</span>,</span><br><span class="line">      label: <span class="type">Double</span>,</span><br><span class="line">      weights: <span class="type">Vector</span>,</span><br><span class="line">      cumGradient: <span class="type">Vector</span>): <span class="type">Double</span> = {</span><br><span class="line">    <span class="keyword">val</span> dotProduct = dot(data, weights)</span><br><span class="line">    <span class="comment">// Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))</span></span><br><span class="line">    <span class="comment">// Therefore the gradient is -(2y - 1)*x</span></span><br><span class="line">    <span class="keyword">val</span> labelScaled = <span class="number">2</span> * label - <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">1.0</span> &amp;gt; labelScaled * dotProduct) {</span><br><span class="line">      axpy(-labelScaled, data, cumGradient)</span><br><span class="line">      <span class="number">1.0</span> - labelScaled * dotProduct</span><br><span class="line">    } <span class="keyword">else</span> {</span><br><span class="line">      <span class="number">0.0</span></span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
</div>

<div class="org-src-container">

<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line"> * :: DeveloperApi ::</span><br><span class="line"> * Updater for L2 regularized problems.</span><br><span class="line"> *          R(w) = 1/2 ||w||^2</span><br><span class="line"> * Uses a step-size decreasing with the square root of the number of iterations.</span><br><span class="line"> */</span></span><br><span class="line"><span class="annotation">@DeveloperApi</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SquaredL2Updater</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">Updater</span> {</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(</span></span><br><span class="line">      weightsOld: <span class="type">Vector</span>,</span><br><span class="line">      gradient: <span class="type">Vector</span>,</span><br><span class="line">      stepSize: <span class="type">Double</span>,</span><br><span class="line">      iter: <span class="type">Int</span>,</span><br><span class="line">      regParam: <span class="type">Double</span>): (<span class="type">Vector</span>, <span class="type">Double</span>) = {</span><br><span class="line">    <span class="comment">// add up both updates from the gradient of the loss (= step) as well as</span></span><br><span class="line">    <span class="comment">// the gradient of the regularizer (= regParam * weightsOld)</span></span><br><span class="line">    <span class="comment">// w&apos; = w - thisIterStepSize * (gradient + regParam * w)</span></span><br><span class="line">    <span class="comment">// w&apos; = (1 - thisIterStepSize * regParam) * w - thisIterStepSize * gradient</span></span><br><span class="line">    <span class="keyword">val</span> thisIterStepSize = stepSize / math.sqrt(iter)</span><br><span class="line">    <span class="keyword">val</span> brzWeights: <span class="type">BV</span>[<span class="type">Double</span>] = weightsOld.asBreeze.toDenseVector</span><br><span class="line">    brzWeights :*= (<span class="number">1.0</span> - thisIterStepSize * regParam)</span><br><span class="line">    brzAxpy(-thisIterStepSize, gradient.asBreeze, brzWeights)</span><br><span class="line">    <span class="keyword">val</span> norm = brzNorm(brzWeights, <span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">    (<span class="type">Vectors</span>.fromBreeze(brzWeights), <span class="number">0.5</span> * regParam * norm * norm)</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></table></figure>
</div>

<p>
&#x6B64;&#x8282;&#x4E2D;, <a href="#code">1</a> &#x5C55;&#x793A;&#x4E86; <code>GradientDescent</code> &#x7684;&#x4E3B;&#x8981;&#x6267;&#x884C;&#x903B;&#x8F91;&#x3002; &#x91CD;&#x590D;&#x6267;&#x884C; <code>numIterations</code> &#x6B21;&#x4EE5;&#x83B7;&#x5F97;&#x6700;&#x7EC8;&#x7684; \( w \)&#x3002;
</p>

<p>
&#x9996;&#x5148;, <code>data.sample</code> &#x901A;&#x8FC7; <code>miniBatchFraction</code> &#x53D6;&#x4E00;&#x90E8;&#x5206;&#x6837;&#x672C;. &#x7136;&#x540E;&#x4F7F;&#x7528; <code>treeAggregate</code> &#x3002;
&#x5728; <code>seqOp</code> &#x4E2D;, <code>gradientSum</code> &#x4F1A;&#x901A;&#x8FC7; <code>axpy(y, b_x, c._1)</code> &#x66F4;&#x65B0;&#xFF0C;&#x5982;&#x679C; \( y\langle w, x \rangle &lt; 1 \)&#xFF0C;&#x5373;&#x5206;&#x7C7B;&#x9519;&#x8BEF;&#x3002;
&#x5728; <code>combOp</code> &#x4E2D;, <code>gradientSum</code> &#x901A;&#x8FC7; <code>c1._1 += c2._1</code> &#x88AB;&#x96C6;&#x5408;&#x8D77;&#x6765;&#x3002; &#x5F53;&#x83B7;&#x5F97; <code>gradientSum</code> &#x540E;, &#x6211;&#x4EEC;&#x5C31;&#x53EF;&#x4EE5;&#x8BA1;&#x7B97; <code>step</code> &#x548C; <code>gradient</code> &#x4E86;&#x3002;
&#x6700;&#x540E;, &#x6211;&#x4EEC;&#x4F7F;&#x7528; <code>axpy(-step, gradient, weights)</code> &#x66F4;&#x65B0; <code>weights</code> &#x3002;
</p>

<div class="org-src-container">
<label class="org-src-name">GradientDescent &#x4EE3;&#x7801;&#x7247;&#x65AD;</label>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (!converged &amp;amp;&amp;amp; i &amp;lt;= numIterations) {</span><br><span class="line">  <span class="keyword">val</span> bcWeights = data.context.broadcast(weights)</span><br><span class="line">  <span class="comment">// Sample a subset (fraction miniBatchFraction) of the total data</span></span><br><span class="line">  <span class="comment">// compute and sum up the subgradients on this subset (this is one map-reduce)</span></span><br><span class="line">  <span class="keyword">val</span> (gradientSum, lossSum, miniBatchSize) = data.sample(<span class="literal">false</span>, miniBatchFraction, <span class="number">42</span> + i)</span><br><span class="line">    .treeAggregate((<span class="type">BDV</span>.zeros[<span class="type">Double</span>](n), <span class="number">0.0</span>, <span class="number">0</span>L))(</span><br><span class="line">      seqOp = (c, v) =&amp;gt; {</span><br><span class="line">	<span class="comment">// c: (grad, loss, count), v: (label, features)</span></span><br><span class="line">	<span class="keyword">val</span> l = gradient.compute(v._2, v._1, bcWeights.value, <span class="type">Vectors</span>.fromBreeze(c._1))</span><br><span class="line">	(c._1, c._2 + l, c._3 + <span class="number">1</span>)</span><br><span class="line">      },</span><br><span class="line">      combOp = (c1, c2) =&amp;gt; {</span><br><span class="line">	<span class="comment">// c: (grad, loss, count)</span></span><br><span class="line">	(c1._1 += c2._1, c1._2 + c2._2, c1._3 + c2._3)</span><br><span class="line">      })</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (miniBatchSize &amp;gt; <span class="number">0</span>) {</span><br><span class="line">    <span class="comment">/**</span><br><span class="line">     * lossSum is computed using the weights from the previous iteration</span><br><span class="line">     * and regVal is the regularization value computed in the previous iteration as well.</span><br><span class="line">     */</span></span><br><span class="line">    stochasticLossHistory.append(lossSum / miniBatchSize + regVal)</span><br><span class="line">    <span class="keyword">val</span> update = updater.compute(</span><br><span class="line">      weights, <span class="type">Vectors</span>.fromBreeze(gradientSum / miniBatchSize.toDouble),</span><br><span class="line">      stepSize, i, regParam)</span><br><span class="line">    weights = update._1</span><br><span class="line">    regVal = update._2</span><br><span class="line"></span><br><span class="line">    previousWeights = currentWeights</span><br><span class="line">    currentWeights = <span class="type">Some</span>(weights)</span><br><span class="line">    <span class="keyword">if</span> (previousWeights != <span class="type">None</span> &amp;amp;&amp;amp; currentWeights != <span class="type">None</span>) {</span><br><span class="line">      converged = isConverged(previousWeights.get,</span><br><span class="line">	currentWeights.get, convergenceTol)</span><br><span class="line">    }</span><br><span class="line">  } <span class="keyword">else</span> {</span><br><span class="line">    logWarning(s<span class="string">&quot;Iteration ($i/$numIterations). The size of sampled batch is zero&quot;</span>)</span><br><span class="line">  }</span><br><span class="line">  i += <span class="number">1</span></span><br></pre></td></tr></table></figure>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> &#x5B9E;&#x9A8C;&#x548C;&#x6027;&#x80FD;</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> &#x6B63;&#x786E;&#x6027;&#x9A8C;&#x8BC1;</h3>
<div class="outline-text-3" id="text-3-1">
<p>
&#x6211;&#x4EEC;&#x6A21;&#x62DF;&#x4E86;&#x4E00;&#x4E9B;&#x7B80;&#x5355;&#x7684; 2D &#x548C; 3D &#x6570;&#x636E;&#x6765;&#x9A8C;&#x8BC1;&#x6B63;&#x786E;&#x6027;&#x3002;
</p>

<div id="2d-linear" class="figure">
<p><img src="/teaching_ml/2016/08/30/svm/2d_linear.png" alt="2d_linear.png">
</p>
<p><span class="figure-number">Figure 3:</span> 2D linear</p>
</div>


<div id="3d-linear" class="figure">
<p><img src="/teaching_ml/2016/08/30/svm/3d_linear.png" alt="3d_linear.png">
</p>
<p><span class="figure-number">Figure 4:</span> 3D linear</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> &#x6536;&#x655B;&#x901F;&#x5EA6;</h3>
<div class="outline-text-3" id="text-3-2">
<p>
&#x6211;&#x4EEC;&#x6BD4;&#x8F83;&#x4E24;&#x79CD;&#x5B9E;&#x73B0;&#x7684;&#x6536;&#x655B;&#x901F;&#x5EA6;&#x5DEE;&#x5F02;&#x3002;&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528; 5GB &#x5E26;&#x6709; 1000 &#x4E2A;&#x7279;&#x5F81;&#x7684;&#x6A21;&#x62DF;&#x6570;&#x636E;&#x3002;&#x4F7F;&#x7528; 4 &#x4E2A; executors &#x5E76;&#x8FED;&#x4EE3; 100 &#x6B21;&#x3002;
</p>


<div id="convergence1" class="figure">
<p><img src="/teaching_ml/2016/08/30/svm/step1.png" alt="step1.png">
</p>
<p><span class="figure-number">Figure 5:</span> before aligning Y axis</p>
</div>


<div id="convergence2" class="figure">
<p><img src="/teaching_ml/2016/08/30/svm/step2.png" alt="step2.png">
</p>
<p><span class="figure-number">Figure 6:</span> after aligning Y axis</p>
</div>
</div>
</div>
</div>


<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> &#x53C2;&#x8003;&#x6587;&#x732E;</h2>
<div class="outline-text-2" id="text-4">
<ol class="org-ol">
<li>Zaharia, Matei, et al. &quot;Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing.&quot; Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association, 2012
</li>
<li>Zaharia, Matei, et al. &quot;Spark: cluster computing with working sets.&quot; Proceedings of the 2nd USENIX conference on Hot topics in cloud computing. Vol. 10. 2010
</li>
<li>Shalev-Shwartz, Shai, et al. &quot;Pegasos: Primal estimated sub-gradient solver for svm.&quot; Mathematical programming 127.1 (2011): 3-30
</li>
</ol>
</div>
</div>

Last Updated 2017-08-09 &#x4E09; 16:31.<br>Render by <a href="https://github.com/CodeFalling/hexo-renderer-org" target="_blank" rel="external">hexo-renderer-org</a> with <a href="http://www.gnu.org/software/emacs/" target="_blank" rel="external">Emacs</a> 24.5.1 (<a href="http://orgmode.org" target="_blank" rel="external">Org</a> mode 8.2.10)

      
    </div>
    <footer class="article-footer">
      <a data-url="http://transwarpio.github.io/2016/08/30/svm/" data-id="cj6g682k0000ggq9s3m38jo9z" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/teaching_ml/2016/12/01/TF-Introduction/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          TF-Introduction
        
      </div>
    </a>
  
  
    <a href="/teaching_ml/2016/07/05/mxnet/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">mxnet 概述</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/teaching_ml/categories/数据挖掘/">数据挖掘</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/teaching_ml/tags/关联规则/">关联规则</a></li><li class="tag-list-item"><a class="tag-list-link" href="/teaching_ml/tags/数据挖掘/">数据挖掘</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/teaching_ml/tags/关联规则/" style="font-size: 10px;">关联规则</a> <a href="/teaching_ml/tags/数据挖掘/" style="font-size: 10px;">数据挖掘</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/teaching_ml/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/teaching_ml/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/teaching_ml/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/teaching_ml/archives/2016/07/">July 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/teaching_ml/2017/08/17/时间序列分析/">时间序列分析</a>
          </li>
        
          <li>
            <a href="/teaching_ml/2017/08/16/分词和HMM/">分词和HMM</a>
          </li>
        
          <li>
            <a href="/teaching_ml/2017/08/15/最大熵模型/">最大熵模型</a>
          </li>
        
          <li>
            <a href="/teaching_ml/2017/08/14/NLP/">[NLP]</a>
          </li>
        
          <li>
            <a href="/teaching_ml/2017/08/11/Word2vec/">[Word2vec]</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 transwarpio<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/teaching_ml/" class="mobile-nav-link">Home</a>
  
    <a href="/teaching_ml/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/teaching_ml/fancybox/jquery.fancybox.css">
  <script src="/teaching_ml/fancybox/jquery.fancybox.pack.js"></script>


<script src="/teaching_ml/js/script.js"></script>

  </div>
</body>
</html>